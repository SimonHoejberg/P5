\section{Intelligent Agents}

As \namep is an autonomous turret and needs to be able to hit a moving target,
it needs to have some intelligence in order to determine how best to hit the
target. The turret can be considered intelligent when its decisions
are explainable by computations and its intelligence can be judged by:

\begin{enumerate}
  \item If what it does is appropriate to its circumstances and goals.
  \item It is flexible to changing environments and changing goals.
  \item It learns from experience.
  \item It makes appropriate choices given its perceptual and computational
  limits.
\end{enumerate}
%See MI book, chapter 1.1 p.4

In order to do this \namep needs to be able to represent the knowledge in a
suitable way that allows it to work it into a suitable solution.


\section{Knowledge Representation}
The general way of solving problems is by having a representation of the
knowledge needed to solve the problem, then computing an output and interpret
that output into a solution.\nl

The representation is part of a represntation scheme, which specifies the form
of the knowledge. All the knowledge stored on the agent that is represented by
this represntation scheme is the knowledge base. In the case of \namep this is
the knowledge about the movement of the target, the vertical angle of the canon
and the horisontal angle of the turret.\nl

The knowledge base should include what makes up a solution to the problem. This
means that we need to figure out wether it matters if the answer is incorrect or
incomplete. To do this four categories of solutions is considered:

\begin{itemize}
  \item Optimal solution - The best solution to the problem
  \item satisficing solution - A solution that is good enough according to the
  description of the solution
  \item Approximately optimal solution - A solution that is close to the optimal
  solution
  \item Probable solution - A solution that is likely to be a solution but is
  not guaranteed to be.
\end{itemize}

The problem that \namep should be solving is hitting a moving target. This means
that we want any solution where the tagtet is hit which is not necissarily the
optimal solution. 


% A knowledge base is a mixture of perception, reasoning and acting, and functions
% as representation of all the knowledge the agent has.

\section{complexity}
Agents have diffenrent dimensions of complexity. These dimensions are:
\begin{itemize}
  \item  modularity
  \item representation scheme
  \item planning horizon 
  \item sensing uncertainty
  \item effect uncertainty
  \item preference
  \item number of agents
  \item learning
  \item computational limits
\end{itemize}

These nine dimensions are needed in order to build an intelligent agent.

\subsection{modularity}
modularity describes how the system can be be broken down into modules that
interact with eachother. These modules can be structured in three ways flat,
modular or hierarchical. If the struture is flat that means that there is only a
single module for the whole system, Modular means that there is more than one
module, where ech module can be understood seperatly and hierarchical means that
each module can be broken down into smaller modules that each can be understood
on their own. \namep is somewhat modular due to the fact that it has different
tasks that can each be a module of its own. 

\subsection{representation scheme}
The representation scheme describes the world in terms of states. The agent uses
these states to reason with. The states can also have features that each has a
value. This decreases the amount of states needed to reason with. These features
can depend on relations and individuals, where each possible relationship
between individuals has a feature. This further decraeses the amount of states
needed.






-------something about states---------
??? - maybe or maybe not

--------Knowledge base (s1.3)---------
AI is about reasoning
An agent is a coupling of perception, reasoning and acting.

Its actions depend on:
- prior knowledge about the agent and the environment
- history of interaction with the environment, which is composed of:
+ observation of the current environents
+ past experiences of previous actions and observations or other data, from
which it can learn
- goals that it must try to achieve or preferences over states of the world
- Abilites which are the primitive actions it is capable of carrying out
(consider using fig1.3 p11)

Problems do you usually not have clear solutions
To solve a problem a designer must:
- flesh out the task and determine what constitutes a solution
- represent the problem in a language with which a computer can reason
- use the computer to compute an output, which is an answer presented to a user
or a sequence
(Consider using fig1.4 p12)

A knowledge base is the representation of all of the knowledge stored on the
agent. A representation should be:
- rich enough to express the knowledge needed to solve the problem
- as close to the problem as possible
- amenable to efficient computation
- able to be acquired from people, data and past experience

Questions needed to be considered when given a problem:
- what is a solution, and how good must a solution be?
- how can a problem be represented?
- how can the agent compute an output that can be interpreted as a solution to
the problem? what about worst and average cases?

Much work in AI is motivated by commonsense reasoning

there are 4 common classes of solutions, they are not exclusive:
- optimal solutions
- satisficing solution --> satisfying + sufficient
- approximate optimal solutions
- probable solution

 -------- Dimensions of complexity ---------
Modularity:
flat - modular - hierachical

Representation scheme:
States - features - relations -propositition

Planning Horizon:
non-planning - finite horizon - indefinite horizon - infinite horizon

Uncertainty:
- Sensing uncertainty:
+ Fully observable
+ Partially observable

- Effect uncertainty:
+ Deterministic
+ Stochastic

Preference:
- goals are either achivement goals or maintenance goals
- complex preferences, ordinal preference, cardinal preference

Number of agents:
- single agent
- multiple agents

Learning:
- Knowledge is given
- knowledge is learned

Computational limits:
- Perfect rationality
- bounded rationality

------- Reasoning under uncertainty (ch6)-------
propability as a measure of belief is Bayesian propability/subjective
propability.





% -------What is an agent (S1.1 p4) --------
% 
% An agent is something that acts in an environment.
% An agent acts intelligent when:
% - what it does is appropriate for its circumstances and its goals
% - it is flexible to changing environments and changing goals
% - it learns from experience
% - it makes appropriate choices given its perceptual and computational
% limitation. It typically cannot observe the state of the world and has finite
% memory and limited time.






